{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/steel-defect-detection/blob/master/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjUM7lLshHhe",
        "colab_type": "text"
      },
      "source": [
        "github.com 대신 https://colab.research.google.com/github/ 입력 -->\n",
        "\n",
        "https://colab.research.google.com/github/secutron/steel-defect-detection/blob/master/Training.ipynb\n",
        "\n",
        "\n",
        "\n",
        "회사에서 dataset 다운로드 하면 중간에 끊김 --> \n",
        "\n",
        "크롬에서 ctrl+j 에서 끊긴 상태에서 지속적으로 다시시도\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y9JQIIhvA97c"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/severstal.jpg?raw=1' width=400px align=right style=\"float:right\">\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## Severstal: Steel Defect Detection\n",
        "### - Detect and classify defects in steel\n",
        "\n",
        "### by Karthik Kumar Billa    \n",
        "### [GitHub](https://github.com/rook0falcon)  |   [LinkedIn](https://www.linkedin.com/in/karthik-kumar-billa/)  |  [Kaggle](https://www.kaggle.com/knightwisdom)  |  [Medium](https://medium.com/@guildbilla)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HiisZpJg_ou",
        "colab_type": "text"
      },
      "source": [
        "## Notebook for Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z244ibeWA97m"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/image_defects.png?raw=1' width=\"300\" align=right style=\"float:right\" >\n",
        "\n",
        "## 1. Business Problem\n",
        "\n",
        "### 1.1 Introduction\n",
        "\n",
        "Steel is one of the most important building materials of modern times. Steel buildings are <br> resistant to natural and man-made wear which has made the material ubiquitous around <br>  the world. Identifying defects will help make production of steel more efficient. Severstal <br> is leading the charge in efficient steel mining and production.\n",
        "\n",
        "Credits: \n",
        "https://www.kaggle.com/c/severstal-steel-defect-detection/overview\n",
        "\n",
        "### 1.2 Problem description\n",
        "Severstal is now looking to machine learning to improve automation, increase efficiency, <br> and maintain high quality in their production.\n",
        "\n",
        "The production process of flat sheet steel is especially delicate. From heating and rolling, to drying and cutting, several machines touch flat steel by the time it’s ready to ship. Today, Severstal uses images from high frequency cameras to power a defect detection algorithm.\n",
        "\n",
        "This notebook will help engineers improve the algorithm by localizing and classifying surface defects on a steel sheet.\n",
        "\n",
        "### 1.3 Source/Useful Links\n",
        "\n",
        "Data Source: \n",
        "https://www.kaggle.com/c/severstal-steel-defect-detection/data\n",
        "\n",
        "Competition hosting company: \n",
        "https://www.severstal.com/\n",
        "\n",
        "For Classification: Xception: \n",
        "https://keras.io/applications/#xception\n",
        "\n",
        "For Segmentation: Unet - EfficientNetB1: \n",
        "https://github.com/qubvel/segmentation_models\n",
        "\n",
        "Training and predictions: \n",
        "Google Colab https://colab.research.google.com/\n",
        "\n",
        "Installing segmentation_models packages in Kaggle Kernels (useful for making an Inference kernel on Kaggle Platform): \n",
        "https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195\n",
        "\n",
        "Sample submission on kaggle:\n",
        "https://www.kaggle.com/knightwisdom/13012020-sever-submission\n",
        "\n",
        "### 1.4 Business objectives and constraints: \n",
        "\n",
        "1. Maximize dice score\n",
        "2. Multi-label probability estimates\n",
        "3. Defect identification and localization should not take much time. In an ideal situation it is desirable to match with the frequency of cameras. It should finish in a few seconds. Inference kernel should take <= 1 hours run-time.\n",
        "4. Save model weights to make inference possible anytime.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nZWYHKYXHRa0"
      },
      "source": [
        "### Keywords: Steel, Defect, Identification, Localization, Dice coefficient, segmentation models, Tensorflow, Run Length Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sz1VZFEmC2wR"
      },
      "source": [
        "## 2. Machine Learning Problem\n",
        "\n",
        "### 2.1 Data Description\n",
        "Source: https://www.kaggle.com/c/severstal-steel-defect-detection/data\n",
        "\n",
        "<pre>\n",
        "Folder/<br>\n",
        "    sample_submission.csv    3 columns <br>\n",
        "    train.csv                3 columns <br>\n",
        "    test_images/             5506 .jpg images <br>\n",
        "    train_images/            12568 .jpg images <br>\n",
        "</pre>\n",
        "Each image is of **256x1600** resolution.\n",
        "\n",
        "train.csv contains defect present image details. Its columns are: \n",
        "\n",
        "<pre>\n",
        "ImageId, Class, EncodedPixels\n",
        "</pre>\n",
        "Test data ImageIds can be found in sample_submission.csv or can be directly accessed from Image file names.\n",
        "\n",
        "Corresponding images can be accessed from train and test folders with the help of ImageIds.\n",
        "\n",
        "\n",
        "\n",
        "Number of Defect Classes: **4**\n",
        "\n",
        "### 2.2 Translating to Machine Learning Problem\n",
        "\n",
        "#### 2.2.1 Type of Machine Learning Problem\n",
        "\n",
        "There are 4 different classes of steel surface defects and we need to locate the defect => **Multi-label Image Segmentation**\n",
        "\n",
        "#### 2.2.2 Performance Metric\n",
        "\n",
        "**Dice coefficient:** https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
        "\n",
        "This metric is used to gauge similarity of two samples. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
        "<pre>\n",
        "    <img src='https://github.com/secutron/steel-defect-detection/blob/master/dice.jpg?raw=1' width=150px align=left>\n",
        "</pre>\n",
        "where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each [ImageId, ClassId] pair in the test set.<br>\n",
        "Source: https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation\n",
        "\n",
        "#### 2.2.3 Machine Learning Objectives and Constraints\n",
        "\n",
        "**Objective:** \n",
        "1. Maximize Dice coefficient\n",
        "2. Identify and locate the type of defect present in the image. Masks generated after predictions should be converted into EncodedPixels.\n",
        "\n",
        "**EncodedPixels:**<br>\n",
        "In order to reduce the submission file size, our metric uses run-length encoding on the pixel values. Instead of submitting an exhaustive list of indices for your segmentation, you will submit pairs of values that contain a start position and a run length. E.g. '1 3' implies starting at pixel 1 and running a total of 3 pixels (1,2,3).\n",
        "\n",
        "The competition format requires a space delimited list of pairs. For example, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask. The metric checks that the pairs are sorted, positive, and the decoded pixel values are not duplicated. The pixels are numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G6bnYTkEV0dC"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/image_segmentation.jpg?raw=1' width=400px align=right style=\"float:right\">\n",
        "\n",
        "**Image Segmentation:** https://en.wikipedia.org/wiki/Image_segmentation\n",
        "\n",
        "In computer vision, image segmentation is the process of partitioning a digital image<br> into multiple segments (sets of pixels, also known as image objects). The goal of<br> segmentation is to simplify and/or change the representation of an image into<br> something that is more meaningful and easier to analyze. Image segmentation is<br> typically used to locate objects and boundaries (lines, curves, etc.) in images. <br>More precisely, image segmentation is the process of assigning a label to every pixel <br> in an image such that pixels with the same label share certain characteristics.\n",
        "\n",
        "In the adjacent image, the original is hard to analyze with the help of computer vision<br> models. With the help of image segmentation we can partition the image into muliple<br> segments. This will make it easy for the computer to learn from patterns in these<br> multiple segments. For example, each pixel belonging to cars is colored red.\n",
        "\n",
        "[Image source](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.researchgate.net%2Ffigure%2FExample-of-2D-semantic-segmentation-Top-input-image-Bottom-prediction_fig3_326875064&psig=AOvVaw3GW6o5S_EehFEBHNan2k-c&ust=1579835580256000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCNDA7afgmOcCFQAAAAAdAAAAABAD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvwtHRIkg_ox",
        "colab_type": "text"
      },
      "source": [
        "**Preparing environment for Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cq4ij77dRQIY",
        "outputId": "1f780418-b689-4b01-ddc6-2c1c7f8c6cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# Loading google drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "By9JUQqGacpz",
        "outputId": "abe60e6e-0674-4e14-9be1-3e3c2ca16990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "# Using segmentation_models for image segmentation task, https://github.com/qubvel/segmentation_models\n",
        "! pip install segmentation-models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.6/dist-packages (from segmentation-models) (1.0.8)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.18.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.0.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
            "Installing collected packages: efficientnet, image-classifiers, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5mJM2oZJan18",
        "outputId": "6b42c916-f966-43ab-fe14-db2baf6f4400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Import libraries\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from time import time\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\n",
        "from keras.models import Model, load_model\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "from random import random\n",
        "from random import seed\n",
        "\n",
        "# https://github.com/qubvel/segmentation_models\n",
        "import segmentation_models\n",
        "print(segmentation_models.__version__)\n",
        "\n",
        "import segmentation_models as sm\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models import get_preprocessing\n",
        "\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Segmentation Models: using `keras` framework.\n",
            "1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPPYRkZilDEa",
        "colab_type": "code",
        "outputId": "9358381f-e37c-4e8d-8153-07ce26743b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1yQIJ1olqMP",
        "colab_type": "code",
        "outputId": "ce3561aa-7508-4ad5-9d51-a7a0c3d4a3d7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 61
        }
      },
      "source": [
        "# https://www.kaggle.com/secutron01/account 에서 kaggle.json\n",
        "# https://somjang.tistory.com/entry/Google-Colab%EC%97%90%EC%84%9C-Google-Drive%EC%99%80-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cc634d8-d324-4147-aa51-ec82bf6325e1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2cc634d8-d324-4147-aa51-ec82bf6325e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRWSkvNGlG2h",
        "colab_type": "code",
        "outputId": "6e34eadd-8710-47bb-efc7-61a454fab207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!kaggle competitions download -c severstal-steel-defect-detection"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 146, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "IOError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTV-a64eaqak",
        "outputId": "7b964c7b-a63e-48fa-dff5-d324e0ad2d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# https://stackoverflow.com/questions/31984387/command-line-for-7z-to-extract-specific-files-from-specific-folders-inside-an-ar\n",
        "# extracting raw data\n",
        "! 7z e '/content/drive/My Drive/severstal_february/archive.zip' -oA1_train       train_images/*.jpg\n",
        "! 7z e '/content/drive/My Drive/severstal_february/archive.zip' -oA3_trainlabels train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/My Drive/severstal_february/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "ERROR: No such file or directory\n",
            "/content/drive/My Drive/severstal_february/archive.zip\n",
            "\n",
            "\n",
            "\n",
            "System ERROR:\n",
            "Unknown error -2147024894\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan /content/drive/My Drive/severstal_february/\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "ERROR: No such file or directory\n",
            "/content/drive/My Drive/severstal_february/archive.zip\n",
            "\n",
            "\n",
            "\n",
            "System ERROR:\n",
            "Unknown error -2147024894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bMCtF7pkayu1",
        "outputId": "600a9ec8-4590-4c10-b49d-68ca70e82844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "train_path = '/content/A1_train/'\n",
        "train_image_names = os.listdir(train_path)\n",
        "trainLabels = pd.read_csv('/content/A3_trainlabels/train.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-528468b4058e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/A1_train/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_image_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrainLabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/A3_trainlabels/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/A1_train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr3omtTYg_pG",
        "colab_type": "text"
      },
      "source": [
        "**Generating X_train, X_val and X_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BZIJpmZwa1Rt",
        "colab": {}
      },
      "source": [
        "train_image_names[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nksKk29ia38R",
        "colab": {}
      },
      "source": [
        "tr_img_id = []\n",
        "tr_cls_id = []\n",
        "for i in os.listdir(train_path):\n",
        "    tr_img_id.append(i)\n",
        "    tr_cls_id.append(1)\n",
        "    tr_img_id.append(i)\n",
        "    tr_cls_id.append(2)\n",
        "    tr_img_id.append(i)\n",
        "    tr_cls_id.append(3)\n",
        "    tr_img_id.append(i)\n",
        "    tr_cls_id.append(4)\n",
        "train_img_nms = pd.DataFrame(tr_img_id,columns=['ImageId'])\n",
        "train_img_nms['ClassId'] = tr_cls_id\n",
        "train_img_nms.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrQKcQGLa4m1",
        "colab": {}
      },
      "source": [
        "train_df = pd.merge(train_img_nms, trainLabels,how='outer',on=['ImageId','ClassId'])\n",
        "train_df = train_df.fillna('')\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Rza4m20a6pg",
        "colab": {}
      },
      "source": [
        "train_data = pd.pivot_table(train_df, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\n",
        "train_data = train_data.reset_index()\n",
        "train_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4']\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a3jt6Kkda8P4",
        "colab": {}
      },
      "source": [
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if all((train_data['Defect_1'][i]=='',train_data['Defect_2'][i]=='',train_data['Defect_3'][i]=='',train_data['Defect_4'][i]=='')):\n",
        "        tmp.append(0)\n",
        "    else:\n",
        "        tmp.append(1)\n",
        "train_data['hasDefect'] = tmp\n",
        "\n",
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if train_data['Defect_1'][i]=='':\n",
        "        tmp.append(0)\n",
        "    else:\n",
        "        tmp.append(1)\n",
        "train_data['hasDefect_1'] = tmp\n",
        "\n",
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if train_data['Defect_2'][i]=='':\n",
        "        tmp.append(0)\n",
        "    else:\n",
        "        tmp.append(1)\n",
        "train_data['hasDefect_2'] = tmp\n",
        "\n",
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if train_data['Defect_3'][i]=='':\n",
        "        tmp.append(0)\n",
        "    else:\n",
        "        tmp.append(1)\n",
        "train_data['hasDefect_3'] = tmp\n",
        "\n",
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if train_data['Defect_4'][i]=='':\n",
        "        tmp.append(0)\n",
        "    else:\n",
        "        tmp.append(1)\n",
        "train_data['hasDefect_4'] = tmp\n",
        "\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "svvC_UxKa_q3",
        "colab": {}
      },
      "source": [
        "# For stratified sampling, stratified based on minority label priority\n",
        "# Label 2 : 247\n",
        "# Label 4 : 801\n",
        "# Label 1 : 897\n",
        "# Label 3 : 5150\n",
        "tmp = []\n",
        "for i in range(len(train_data)):\n",
        "    if train_data['hasDefect_2'].iloc[i]==1:\n",
        "        tmp.append(2)\n",
        "    elif train_data['hasDefect_4'].iloc[i]==1:\n",
        "        tmp.append(4)\n",
        "    elif train_data['hasDefect_1'].iloc[i]==1:\n",
        "        tmp.append(1)\n",
        "    elif train_data['hasDefect_3'].iloc[i]==1:\n",
        "        tmp.append(3)\n",
        "    else:\n",
        "        tmp.append(0)\n",
        "train_data['stratify']=tmp\n",
        "train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdH3AKrag_ph",
        "colab_type": "text"
      },
      "source": [
        "**Train. Validation and Test split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yY84nQGcbASc",
        "colab": {}
      },
      "source": [
        "X = train_data.copy()\n",
        "X_train, X_test = train_test_split(X, test_size = 0.1, stratify = X['stratify'],random_state=42)\n",
        "X_train, X_val = train_test_split(X_train, test_size = 0.2, stratify = X_train['stratify'],random_state=42)\n",
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DRW0XYU2TloD"
      },
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i_tnKfORbrH9",
        "colab": {}
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ziRK__-lb0hk",
        "colab": {}
      },
      "source": [
        "# Sample Image\n",
        "fig, ax = plt.subplots(1,1,figsize=(8, 7))\n",
        "img = Image.open(str(train_path + X_train.ImageId.iloc[0]))\n",
        "plt.imshow(img)\n",
        "ax.set_title(X_train.ImageId.iloc[0])\n",
        "plt.show()\n",
        "print(img.size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPgUFW5jg_ps",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The images have 1600x256 pixel resolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r4NMKPPXcP78",
        "colab": {}
      },
      "source": [
        "print(\"No. of Images in train set: \", X_train.shape[0],'\\n','-'*50)\n",
        "\n",
        "tmp = [sum(X_train['hasDefect_1']==1),\n",
        "       sum(X_train['hasDefect_2']==1),\n",
        "       sum(X_train['hasDefect_3']==1),\n",
        "       sum(X_train['hasDefect_4']==1)]\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(x=['1','2','3','4'],y=tmp,palette = \"rocket\")\n",
        "ax.set_title(\"Number of images for each label\")\n",
        "ax.set_xlabel(\"Label\")\n",
        "plt.show()\n",
        "print(\"No. of Images having: Label 1 = {}, Label 2 = {}, Label 3 = {}, Label 4 = {}\".format(tmp[0],tmp[1],tmp[2],tmp[3]),'\\n','-'*50)\n",
        "\n",
        "tmp = (X_train['hasDefect_1']+X_train['hasDefect_2']+X_train['hasDefect_3']+X_train['hasDefect_4']).value_counts()\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(x=['No label','1','2'],y=tmp,palette = \"rocket\")\n",
        "ax.set_title(\"Number of labels for each image\")\n",
        "ax.set_xlabel(\"Label\")\n",
        "plt.show()\n",
        "print(\"No. of Images with no defects: {}, with only one label: {}, with two labels: {}\".format(tmp[0],tmp[1],tmp[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ac8V-rrhg5NW"
      },
      "source": [
        "#### Observation: The dataset is highly imbalanced. This will make predicting minority class (Class 2) difficult. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y142Wz-L5UCX",
        "colab": {}
      },
      "source": [
        "# 5 images having no defects\n",
        "tmp = []\n",
        "cnt=0\n",
        "print(\"Sample images with no defects:\")\n",
        "for i in X_train['ImageId'][X_train['hasDefect']==0]:\n",
        "    if cnt<5:\n",
        "        fig, ax = plt.subplots(1,1,figsize=(8, 7))\n",
        "        img = Image.open(str(train_path + i))\n",
        "        plt.imshow(img)\n",
        "        ax.set_title(i)\n",
        "        plt.show()\n",
        "        cnt+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtmpNaeTg_p0",
        "colab_type": "text"
      },
      "source": [
        "### Observation: \n",
        "The surface of the non-defective steel may contain different features or profile. It has to be noted that that presence of defect is limited to the 4 types of defects in this dataset. The steel surface may contain other defects but those should not be detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VuscbYKvdzML",
        "colab": {}
      },
      "source": [
        "# We need a function to convert EncodedPixels into mask\n",
        "# https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
        "\n",
        "def rle2mask(mask_rle, shape=(1600,256)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (width,height) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    This function is specific to this competition\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape).T\n",
        "\n",
        "def mask2rle(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    This function is specific to this competition\n",
        "    '''\n",
        "    pixels= img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_InNrDg_dG6M",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Visualization: Sample images having defect\n",
        "for k in [1,2,3,4]:\n",
        "    tmp = []\n",
        "    cnt=0\n",
        "    print(\"Sample images with Class {} defect:\".format(k))\n",
        "    for i in X_train[X_train[f'hasDefect_{k}']==1][['ImageId',f'Defect_{k}']].values:\n",
        "        if cnt<5:\n",
        "            fig, (ax1,ax2) = plt.subplots(nrows = 1,ncols = 2,figsize=(15, 7))\n",
        "            img = Image.open(str(train_path + i[0]))\n",
        "            ax1.imshow(img)\n",
        "            ax1.set_title(i[0])\n",
        "            cnt+=1\n",
        "            ax2.imshow(rle2mask(i[1]))\n",
        "            ax2.set_title(i[0]+'_mask_'+str(k))\n",
        "            plt.show()\n",
        "    print('-'*80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iTCkg2NvaMOV"
      },
      "source": [
        "### Observation:\n",
        "The regional profile on the masks of defect conataining steel surfaces can be seen to be indistinguishable among different classes. Though defect type 1 can be seen to have multiplte small size regions and defect type 4 images have multiple regions of medium size. Defect type 3 images can be seen to also contain multiple regions of medium size. While defect type 2 and type 3 images can be seen to share some regional characteristics. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJCIJtUbg_p6",
        "colab_type": "text"
      },
      "source": [
        "#### 'area' as a new feature\n",
        "Used for thresholding masks after generating predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sizgQE6Af-Hd",
        "colab": {}
      },
      "source": [
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2,figsize=(12,7))\n",
        "\n",
        "tmp = X_train['Defect_1'][X_train['hasDefect_1']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]]))\n",
        "ax1.hist(tmp.values,bins = 25)\n",
        "ax1.set_xlabel('Defect_1_area')\n",
        "ax1.set_ylabel('Number of Images')\n",
        "\n",
        "\n",
        "tmp = X_train['Defect_2'][X_train['hasDefect_2']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]]))\n",
        "ax2.hist(tmp.values,bins = 25)\n",
        "ax2.set_xlabel('Defect_2_area')\n",
        "ax2.set_ylabel('Number of Images')\n",
        "\n",
        "\n",
        "tmp = X_train['Defect_3'][X_train['hasDefect_3']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]]))\n",
        "ax3.hist(tmp.values,bins = 25)\n",
        "ax3.set_xlabel('Defect_3_area')\n",
        "ax3.set_ylabel('Number of Images')\n",
        "\n",
        "\n",
        "tmp = X_train['Defect_4'][X_train['hasDefect_4']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]]))\n",
        "ax4.hist(tmp.values,bins = 25)\n",
        "ax4.set_xlabel('Defect_4_area')\n",
        "ax4.set_ylabel('Number of Images')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print('-'*50)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "for i in [1,2,3,4]:\n",
        "    tmp = X_train[f'Defect_{i}'][X_train[f'hasDefect_{i}']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]]))\n",
        "    plt.plot(tmp,np.zeros_like(tmp)+i,'o')\n",
        "plt.xlabel('area')\n",
        "plt.ylabel('Defect type')\n",
        "plt.show()\n",
        "print('-'*50)\n",
        "\n",
        "tmp =[]\n",
        "for i in [1,2,3,4]:\n",
        "\n",
        "    tmp.append(X_train[f'Defect_{i}'][X_train[f'hasDefect_{i}']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]])).describe())\n",
        "area_df = pd.DataFrame(tmp)\n",
        "area_df.index=['Defect_1','Defect_2','Defect_3','Defect_4']\n",
        "area_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CIqXZ6rbeBIA"
      },
      "source": [
        "### Observation: \n",
        "There is considerable overlap in the range of area. Minimum area for each defect type can be seen closer to each other. While the maximum is largely different. We can use the minimum and maximum values of area in training images to threshold test image defect predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j308wJl-invd",
        "colab": {}
      },
      "source": [
        "# removing areas below 2 percentile and above 98 percentile to threshold area of predicted masks\n",
        "tmp = []\n",
        "for i in [1,2,3,4]:\n",
        "    tmp_1 = X_train[f'Defect_{i}'][X_train[f'hasDefect_{i}']==1].apply(lambda s: sum([int(k) for k in s.split(' ')[1::2]])).sort_values().reset_index().drop('index',axis=1)\n",
        "    tmp.append([tmp_1.iloc[int(0.02*len(tmp_1))].values[0],tmp_1.iloc[-int(0.02*len(tmp_1))].values[0]])\n",
        "print('Limiting area to above 2 percentile and below 98 percentile values: \\n',tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XwL4aLLAjHDf",
        "colab": {}
      },
      "source": [
        "area_threshold = pd.DataFrame([[500,15500],[700,10000],[1100,160000],[2800,127000]],\n",
        "                               columns=['min','max'], index=['defect_1','defect_2','defect_3','defect_4'])\n",
        "area_threshold # to threshold predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fUvMso7QRTwm"
      },
      "source": [
        "### Summary:\n",
        "Based on range of area for each defect, we will threshold predictions to filter outliers. For e.g. some predicted masks have only 4 pixels that have value 1. Such an image will reduce the performance of the model on the final metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rXuthiw7dl9M"
      },
      "source": [
        "## EDA conclusion: \n",
        "\n",
        "a) The dataset is imbalanced thus we will use stratified sampling for splitting the dataset into train and validation datasets. <br> \n",
        "\n",
        "b) This is a multi-label image segmentation problem. As there are around 50% of images with no defects, it is equally important to identify images with no defects. <br> \n",
        "\n",
        "c) Based on area thresholds from 'test_thresolds' dataframe and class probability thresholds (which are to be determined after predictions from neural networks), we will ensure that number of predicted images per defect will be closer to the values in 'count' column. <br>\n",
        "\n",
        "d) Procedure:\n",
        "  1. We will have a binary classification model to filter images with defects from no defect images. \n",
        "  2. A 4-label classification model to predict probablities of images beloning to each class.\n",
        "  3. 4 segmentation models for four different classes to generate masks for each test image.\n",
        "  4. Convert masks to EncodedPixels and filter them as per classification probabilities.\n",
        "\n",
        "e) We are generating a new solution to the business problem with available libraries: tensorflow, keras and segmentation_models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LbWPqXcSA9-A"
      },
      "source": [
        "### Model architecture:\n",
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/model_arch_new.jpg?raw=1' width=1000px align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK0lra2Fg_qF",
        "colab_type": "text"
      },
      "source": [
        "Blue dots in the Architecture image indicates that an input is being given at that level, while black dot near \"Apply threholds\" correspond to the application of thresholds at the output of predicted masks. At the threshold application level images are filtered based on Defect presence probability, Defect type belongingness and area of the defect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QH4oGBqOnaH3"
      },
      "source": [
        "## 4. Data preparation and Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h7F9tf58kIwa",
        "colab": {}
      },
      "source": [
        "train_segmentation = True\n",
        "train_classification_binary = True\n",
        "train_classification_multi = True\n",
        "epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OJQYJF6jlor",
        "colab": {}
      },
      "source": [
        "# Metrics\n",
        "# For image segmentation\n",
        "# COMPETITION METRIC\n",
        "# https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n",
        "def dice_coef(y_true, y_pred, smooth=K.epsilon()):\n",
        "    '''\n",
        "    This function returns dice coefficient of similarity between y_true and y_pred\n",
        "    Dice coefficient is also referred to as F1_score, but we will use this name for image segmentation models\n",
        "    For example, \n",
        "    let an instance on y_true and y_pred be [[1,1],[0,1]] and [[1,0],[0,1]]\n",
        "    this metric first converts the above into [1,1,0,1] abd [1,0,0,1],\n",
        "    then intersection is calculated as 1*1 + 1*0 + 0*1 + 1*1 = 2 and sum(y_true)+sum(y_pred)= 3+2 = 5\n",
        "    this returns the value (2.* 2 + 10e-7)/(3 + 2 + 10e-7) ~ 0.8    \n",
        "    '''\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Custom metrics, https://stackoverflow.com/questions/59196793/why-are-my-metrics-of-my-cnn-not-changing-with-each-epoch\n",
        "# For clasification\n",
        "def recall_m(y_true, y_pred):\n",
        "    '''\n",
        "    This function returns recall_score between y_true and y_pred\n",
        "    This function is ported as a metric to the Neural Network Models\n",
        "    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n",
        "    as input and returns recall score of the batch\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) # calculates number of true positives\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))      # calculates number of actual positives\n",
        "    recall = true_positives / (possible_positives + K.epsilon())   # K.epsilon takes care of non-zero divisions\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    '''\n",
        "    This function returns precison_score between y_true and y_pred\n",
        "    This function is ported as a metric to the Neural Network Models\n",
        "    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n",
        "    as input and returns prediction score of the batch\n",
        "    '''\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))  # calculates number of true positives\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))      # calculates number of predicted positives   \n",
        "    precision = true_positives /(predicted_positives + K.epsilon()) # K.epsilon takes care of non-zero divisions\n",
        "    return precision\n",
        "    \n",
        "def f1_score_m(y_true, y_pred):\n",
        "    '''\n",
        "    This function returns f1_score between y_true and y_pred\n",
        "    This \n",
        "    This function is ported as a metric to the Neural Network Models\n",
        "    Keras backend is used to take care of batch type training, the metric takes in a batch of y_pred and corresponding y_pred \n",
        "    as input and returns f1 score of the batch\n",
        "    '''\n",
        "    precision = precision_m(y_true, y_pred)  # calls precision metric and takes the score of precision of the batch\n",
        "    recall = recall_m(y_true, y_pred)        # calls recall metric and takes the score of precision of the batch\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "dependencies = {\n",
        "    'recall_m':recall_m,\n",
        "    'precision_m':precision_m,\n",
        "    'dice_coef':dice_coef,\n",
        "    'f1_score_m':f1_score_m,\n",
        "    'dice_loss':sm.losses.dice_loss\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "22S8qHCLndCH"
      },
      "source": [
        "### 4.1 Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3awX3865n1mN"
      },
      "source": [
        "- Train and predict the probability of presence of defects in images ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LSxp0SRXA9-L"
      },
      "source": [
        "### 4.1.1 Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YvsTfaqIkNZO",
        "colab": {}
      },
      "source": [
        "X_train_binary = X_train[['ImageId','hasDefect']]\n",
        "X_val_binary = X_val[['ImageId','hasDefect']]\n",
        "X_test_binary = X_test[['ImageId','hasDefect']]\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_binary.shape, X_val_binary.shape, X_test_binary.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TEMYDXb6jv37",
        "colab": {}
      },
      "source": [
        "# https://keras.io/preprocessing/image/\n",
        "# https://stackoverflow.com/questions/52754492/write-custom-data-generator-for-keras\n",
        "\n",
        "# DataGenerator for the binary classification model with image augmentations\n",
        "\n",
        "train_DataGenerator_1 = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n",
        "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "test_DataGenerator_1 = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_DataGenerator_1.flow_from_dataframe(\n",
        "        dataframe=X_train_binary.astype(str),\n",
        "        directory=train_path,\n",
        "        x_col=\"ImageId\",\n",
        "        y_col=\"hasDefect\",\n",
        "        target_size=(256,512),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_DataGenerator_1.flow_from_dataframe(\n",
        "        dataframe=X_val_binary.astype(str),\n",
        "        directory=train_path,\n",
        "        x_col=\"ImageId\",\n",
        "        y_col=\"hasDefect\",\n",
        "        target_size=(256,512),\n",
        "        batch_size=16,\n",
        "        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xljJEWSdA9_L"
      },
      "source": [
        "### 4.1.2 Binary Classification Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XkfoEPmKlyyz",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "# https://www.youtube.com/watch?v=2U6Jl7oqRkM\n",
        "# Using a pretrained model from keras for classification: \n",
        "# Selecting Xception pretrained model\n",
        "# https://keras.io/applications/\n",
        "\n",
        "base_model = keras.applications.xception.Xception(include_top = False, input_shape = (256,512,3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# and the prediction layer\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k3kOUC_uA9_W"
      },
      "source": [
        "### 4.1.3 Binary Classification Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l1JqFKlkl8cP",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc',f1_score_m,precision_m,recall_m])\n",
        "if train_classification_binary==True:\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_binary_01_02_2020'\n",
        "\n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    # https://keras.io/callbacks/\n",
        "\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_binary_01_02_2020.h5', monitor='val_f1_score_m', mode='max', verbose=1, save_best_only=True)\n",
        "    history = model.fit_generator(train_generator, validation_data = validation_generator, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3mmTDaO-nt0m",
        "colab": {}
      },
      "source": [
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation loss\")\n",
        "ax.plot(x,ty,'b',label = \"loss\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('Loss: BCE')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WWJ8rhUg_qc",
        "colab_type": "text"
      },
      "source": [
        "Tensorboard visualization (similar to above plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PFvN6wsg_qc",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/binary_tensorboard/train_loss.jpg?raw=1' width=600px align = left> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpXGwC-Eg_qd",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Train loss reduction is smooth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJnebE50g_qd",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/binary_tensorboard/val_loss.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Ff5sxwg_qe",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Binary cross entropy loss of the model can be seen to have large variations on validation set. This implies that the model is having tough time generalizing on unseen dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eBgjPoB8n-pg",
        "colab": {}
      },
      "source": [
        "vy = history.history['val_f1_score_m']\n",
        "ty = history.history['f1_score_m']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation f1_score\")\n",
        "ax.plot(x,ty,'b',label = \"f1_score\") # Train set\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('Metric: F1_score')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34gGIecWg_qh",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/binary_tensorboard/train_f1.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah13nlDNg_qh",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/binary_tensorboard/val_f1.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5XGYofFg_qi",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Similar to BCE loss, f1_score on validation set can be seen to vary a lot this implies that the training dataset is insufficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0jz00YgfoAy7",
        "colab": {}
      },
      "source": [
        "vy = history.history['val_precision_m']\n",
        "ty = history.history['precision_m']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation precision_m\")\n",
        "ax.plot(x,ty,'b',label = \"precision_m\") # Train set\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('Metric: Precision')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiCNhc4Tg_ql",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Precision can be seen to improve smoothly at every epoch. Precision tells how many predicted positives are actually positive. The behavior implies that the performance of the model on successfully predicting negatives is good. High precision implies less false positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JXDtft4XoDdn",
        "colab": {}
      },
      "source": [
        "vy = history.history['val_recall_m']\n",
        "ty = history.history['recall_m']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation recall\")\n",
        "ax.plot(x,ty,'b',label = \"recall\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('Metric: recall')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eEj24S-g_qp",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Recall can be seen to vary largely at every epoch. Recall tells how many positives are predicted out of total actual positives. The behavior implies that the performance of the model on successfully predicting positives is poor. High recall implies less false negatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35dxRTxPg_qq",
        "colab_type": "text"
      },
      "source": [
        "**F1_score metric Justification:** For this image segmentation task, it is very important to achieve a high precision high recall model. Thus, f1_score is a suitable metric for the classification models. The classification model is monitored for high f1_score for saving model weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sVGWKcOYA9_m"
      },
      "source": [
        "### 4.1.4 Binary Classification Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tsb7mMbYuDpk",
        "colab": {}
      },
      "source": [
        "# Loading best model trained on binary classification\n",
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_binary_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PcueggpnuMRO",
        "colab": {}
      },
      "source": [
        "# During evaluation image augmentations are not to be included thus the DataGenerators are redefined.\n",
        "\n",
        "train_generator = test_DataGenerator_1.flow_from_dataframe(dataframe=X_train_binary.astype(str),\n",
        "                                                           directory=train_path,\n",
        "                                                           x_col=\"ImageId\",\n",
        "                                                           y_col=\"hasDefect\",\n",
        "                                                           target_size=(256,512),\n",
        "                                                           batch_size=16,\n",
        "                                                           class_mode='binary',\n",
        "                                                           shuffle=False)\n",
        "\n",
        "validation_generator = test_DataGenerator_1.flow_from_dataframe(dataframe=X_val_binary.astype(str),\n",
        "                                                                directory=train_path,\n",
        "                                                                x_col=\"ImageId\",\n",
        "                                                                y_col=\"hasDefect\",\n",
        "                                                                target_size=(256,512),\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='binary',\n",
        "                                                                shuffle=False)\n",
        "\n",
        "test_generator = test_DataGenerator_1.flow_from_dataframe(dataframe=X_test_binary.astype(str),\n",
        "                                                                directory=train_path,\n",
        "                                                                x_col=\"ImageId\",\n",
        "                                                                y_col=\"hasDefect\",\n",
        "                                                                target_size=(256,512),\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='binary',\n",
        "                                                                shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uSVlu3Njudxl",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(train_generator,verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m9s1xkCeuiHT",
        "colab": {}
      },
      "source": [
        "val_evaluate = model.evaluate(validation_generator,verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(val_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T1DkP9w-uzIO",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_generator,verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKeCi8Ecg_q-",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The model is having good performance on train, validation and test dataset. The values of loss and metrics can be seen to be similar in these datasets. This tells that the model is not overfitting on dataset. The f1_score of 0.921 on validation dataset is acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LUwuuXp3qlsQ"
      },
      "source": [
        "## 4.2 Multi-label classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d-ILuJ3mA-AS"
      },
      "source": [
        "### 4.2.1 Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jU5xuFBwmT2",
        "colab": {}
      },
      "source": [
        "X_train_multi = X_train[['ImageId','hasDefect_1','hasDefect_2','hasDefect_3','hasDefect_4']][X_train['hasDefect']==1]\n",
        "X_val_multi = X_val[['ImageId','hasDefect_1','hasDefect_2','hasDefect_3','hasDefect_4']][X_val['hasDefect']==1]\n",
        "X_test_multi = X_test[['ImageId','hasDefect_1','hasDefect_2','hasDefect_3','hasDefect_4']][X_test['hasDefect']==1]\n",
        "\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(X_train_multi.shape, X_val_multi.shape, X_test_multi.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZRi1XjrxICk",
        "colab": {}
      },
      "source": [
        "# https://keras.io/preprocessing/image/\n",
        "# https://stackoverflow.com/questions/52754492/write-custom-data-generator-for-keras\n",
        "\n",
        "# DataGenerator for the multi label classification model with image augmentations\n",
        "train_DataGenerator_2 = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n",
        "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "\n",
        "train_generator = train_DataGenerator_2.flow_from_dataframe(\n",
        "        dataframe=X_train_multi.astype(str),\n",
        "        directory='/content/A1_train',\n",
        "        x_col=\"ImageId\",\n",
        "        y_col=[\"hasDefect_1\",\"hasDefect_2\",\"hasDefect_3\",\"hasDefect_4\"],\n",
        "        target_size=(256,512),\n",
        "        batch_size=16,\n",
        "        class_mode='other')\n",
        "\n",
        "\n",
        "test_DataGenerator_2 = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = test_DataGenerator_2.flow_from_dataframe(\n",
        "        dataframe=X_val_multi.astype(str),\n",
        "        directory='/content/A1_train',\n",
        "        x_col=\"ImageId\",\n",
        "        y_col=[\"hasDefect_1\",\"hasDefect_2\",\"hasDefect_3\",\"hasDefect_4\"],\n",
        "        target_size=(256,512),\n",
        "        batch_size=16,\n",
        "        class_mode='other')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LhesXUG8A-Ak"
      },
      "source": [
        "### 4.2.2 Multi-Label Classification Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLwDH22YxgII",
        "colab": {}
      },
      "source": [
        "# Using a pretrained model from keras for classification: \n",
        "# Selecting Xception pretrained model\n",
        "# https://keras.io/applications/\n",
        "\n",
        "base_model = keras.applications.xception.Xception(include_top = False, input_shape = (256,512,3))\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "# let's add fully-connected layers\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "# and the prediction layer\n",
        "predictions = Dense(4, activation='sigmoid')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lsjf3vd_A-A2"
      },
      "source": [
        "### 4.2.3 Multi-label Classification Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZPavDzQx1UF",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc',f1_score_m,precision_m,recall_m])\n",
        "if train_classification_multi==True:\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_multi_Defect_01_02_2020'\n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    # https://keras.io/callbacks/\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_multi_01_02_2020.h5', monitor='val_f1_score_m', mode='max', verbose=1, save_best_only=True)\n",
        "    history = model.fit_generator(train_generator, validation_data = validation_generator, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "17fxWR9Axjg0",
        "colab": {}
      },
      "source": [
        "# plot on \"loss\" vs epoch\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation loss\")\n",
        "ax.plot(x,ty,'b',label = \"Train loss\")\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss: Binary Cross Entropy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Vp1oN4g_rT",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/multi_tensorboard/train_loss.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRk-qIX5g_rU",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/multi_tensorboard/val_loss.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q89OeyKpg_rU",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Binary cross entropy loss of the model can be seen to reduce smoothly on validation set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dFtsHqxzyOp3",
        "colab": {}
      },
      "source": [
        "# Plot on f1_score vs epoch\n",
        "vy = history.history['val_f1_score_m']\n",
        "ty = history.history['f1_score_m']\n",
        "x = list(range(1,len(vy)+1))\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.plot(x,vy,'r',label = \"Validation f1 score\")\n",
        "ax.plot(x,ty,'b',label = \"Train score\")\n",
        "ax.set_xlabel('epoch')\n",
        "ax.set_ylabel('Metric: score')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhZXWNzXg_rY",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/multi_tensorboard/train_f1.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3uZpqRBg_rY",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/multi_tensorboard/val_f1.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVZ7HjzHg_rZ",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Similar to BCE loss, f1_score can be seen to smoothly increase on validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qi-LLv-oA-BR"
      },
      "source": [
        "### 4.2.4 Multi-label Classification Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2H0JUbBLyRUz",
        "colab": {}
      },
      "source": [
        "# loading best saved multi_label classification model\n",
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_multi_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MqVnzt20lLm",
        "colab": {}
      },
      "source": [
        "# During evaluation we do not require image augmentations\n",
        "train_generator = test_DataGenerator_2.flow_from_dataframe(dataframe=X_train_multi.astype(str),\n",
        "                                                           directory=train_path,\n",
        "                                                           x_col=\"ImageId\",\n",
        "                                                           y_col=[\"hasDefect_1\",\"hasDefect_2\",\"hasDefect_3\",\"hasDefect_4\"],\n",
        "                                                           target_size=(256,512),\n",
        "                                                           batch_size=16,\n",
        "                                                           class_mode='other',\n",
        "                                                           shuffle=False)\n",
        "\n",
        "validation_generator = test_DataGenerator_2.flow_from_dataframe(dataframe=X_val_multi.astype(str),\n",
        "                                                                directory=train_path,\n",
        "                                                                x_col=\"ImageId\",\n",
        "                                                                y_col=[\"hasDefect_1\",\"hasDefect_2\",\"hasDefect_3\",\"hasDefect_4\"],\n",
        "                                                                target_size=(256,512),\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='other',\n",
        "                                                                shuffle=False)\n",
        "\n",
        "test_generator = test_DataGenerator_2.flow_from_dataframe(dataframe=X_test_multi.astype(str),\n",
        "                                                                directory=train_path,\n",
        "                                                                x_col=\"ImageId\",\n",
        "                                                                y_col=[\"hasDefect_1\",\"hasDefect_2\",\"hasDefect_3\",\"hasDefect_4\"],\n",
        "                                                                target_size=(256,512),\n",
        "                                                                batch_size=16,\n",
        "                                                                class_mode='other',\n",
        "                                                                shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q236_dLs0_26",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(train_generator,verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0YcLAach0_3R",
        "colab": {}
      },
      "source": [
        "val_evaluate = model.evaluate(validation_generator,verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(val_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eO-GPUZV0_3d",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_generator,verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['binary_crossentropy','acc','f1_score_m','precision_m','recall_m'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4VcPPVkg_rv",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The multi-label classification model is generalizing well on unseen data (the values of evaluation on test set and validation set are closer to train set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0y6nykLcq78j"
      },
      "source": [
        "## 4.3 Image segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HnkABBhRA-CK"
      },
      "source": [
        "### 4.3.1 Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p6_zimeJ1RFa",
        "colab": {}
      },
      "source": [
        "# Dividing the datasets w.r.t. Class Label (defect type)\n",
        "train_data_1 = X_train[X_train['hasDefect_1']==1][['ImageId','Defect_1']]\n",
        "train_data_2 = X_train[X_train['hasDefect_2']==1][['ImageId','Defect_2']]\n",
        "train_data_3 = X_train[X_train['hasDefect_3']==1][['ImageId','Defect_3']]\n",
        "train_data_4 = X_train[X_train['hasDefect_4']==1][['ImageId','Defect_4']]\n",
        "\n",
        "val_data_1 = X_val[X_val['hasDefect_1']==1][['ImageId','Defect_1']]\n",
        "val_data_2 = X_val[X_val['hasDefect_2']==1][['ImageId','Defect_2']]\n",
        "val_data_3 = X_val[X_val['hasDefect_3']==1][['ImageId','Defect_3']]\n",
        "val_data_4 = X_val[X_val['hasDefect_4']==1][['ImageId','Defect_4']]\n",
        "\n",
        "test_data_1 = X_test[X_test['hasDefect_1']==1][['ImageId','Defect_1']]\n",
        "test_data_2 = X_test[X_test['hasDefect_2']==1][['ImageId','Defect_2']]\n",
        "test_data_3 = X_test[X_test['hasDefect_3']==1][['ImageId','Defect_3']]\n",
        "test_data_4 = X_test[X_test['hasDefect_4']==1][['ImageId','Defect_4']]\n",
        "\n",
        "train_data_1.columns = train_data_2.columns = train_data_3.columns = train_data_4.columns = ['ImageId','EncodedPixels']\n",
        "val_data_1.columns = val_data_2.columns = val_data_3.columns = val_data_4.columns = ['ImageId','EncodedPixels']\n",
        "test_data_1.columns = test_data_2.columns = test_data_3.columns = test_data_4.columns = ['ImageId','EncodedPixels']\n",
        "\n",
        "print(test_data_1.head())\n",
        "print('-'*50)\n",
        "print(X_train.shape, X_val.shape, X_test.shape)\n",
        "print(train_data_1.shape,val_data_1.shape,test_data_1.shape)\n",
        "print(train_data_2.shape,val_data_2.shape,test_data_2.shape)\n",
        "print(train_data_3.shape,val_data_3.shape,test_data_3.shape)\n",
        "print(train_data_4.shape,val_data_4.shape,test_data_4.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eNNtRqfo_ESn",
        "colab": {}
      },
      "source": [
        "# code reference, https://www.kaggle.com/cdeotte/keras-unet-with-eda# https://www.kaggle.com/cdeotte/keras-unet-with-eda\n",
        "def rle2maskResize(rle):\n",
        "    '''\n",
        "    Generates masks for each image taking RLE as input\n",
        "    Converts run length encoding to an image of shape defined uniform throughout segmentation models: 256x800\n",
        "    Takes EncodedPixels as input, converts into 256x1600 mask and returns a resized mask image of size 256x800\n",
        "    '''\n",
        "    if (pd.isnull(rle))|(rle==''): # If the EncodedPixels string is empty an empty mask is returned\n",
        "        return np.zeros((256,800) ,dtype=np.uint8)\n",
        "\n",
        "    height= 256\n",
        "    width = 1600\n",
        "    mask= np.zeros( width*height ,dtype=np.uint8)\n",
        "\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]-1 # The pixel array definition starts from 1 while array starts from 0\n",
        "    lengths = array[1::2]  # The second element of EncodedPixels is the length denoting number of pixels in successive that are active (value = 1)\n",
        "    for index, start in enumerate(starts):\n",
        "        mask[int(start):int(start+lengths[index])] = 1 # Making \n",
        "    \n",
        "    return mask.reshape((height,width),order='F')[::,::2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Imx6UiRi_H9I",
        "colab": {}
      },
      "source": [
        "# https://www.kaggle.com/cdeotte/keras-unet-with-eda# https://www.kaggle.com/cdeotte/keras-unet-with-eda\n",
        "# https://stackoverflow.com/questions/52754492/write-custom-data-generator-for-keras\n",
        "# DataGenerator custom built for training segmentation models with random image augmentations\n",
        "# \n",
        "class train_DataGenerator_3(keras.utils.Sequence): # with augmentation for training\n",
        "    '''\n",
        "    The DataGenerator takes a batch of ImageIds of batch size 8 and returns Image array to the model with its mask.\n",
        "    With the help of ImageIds the DataGenerator locates the Image file in the path, the image is read and resized from\n",
        "    256 x 1600 to 256x800.\n",
        "    A set of random numbers are generated to generate random Image Augmentations.\n",
        "    Shuffling is enabled during training to include variations in the sequence of images processed at each epoch.\n",
        "    '''\n",
        "    def __init__(self, df, batch_size = 8,  shuffle=True, \n",
        "                 preprocess=None, info={}):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.preprocess = preprocess\n",
        "        self.info = info\n",
        "        self.data_path = '/content/A1_train/'\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __getitem__(self, index): \n",
        "        X = np.empty((self.batch_size,256,800,3),dtype=np.float32)\n",
        "        X1 = np.empty((self.batch_size,256,800,3),dtype=np.float32)\n",
        "\n",
        "        y = np.empty((self.batch_size,256,800,1),dtype=np.int8)\n",
        "        y1 = np.empty((self.batch_size,256,800,1),dtype=np.int8)\n",
        "\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n",
        "            self.info[index*self.batch_size+i]=f\n",
        "            X[i,] = Image.open(self.data_path + f).resize((800,256))           \n",
        "            y[i,:,:,0] = rle2maskResize(self.df['EncodedPixels'].iloc[indexes[i]])\n",
        "        if self.preprocess!=None: X = self.preprocess(X)\n",
        "\n",
        "        # generate some random image augmentations\n",
        "        augment = random()\n",
        "        if augment>0.35:\n",
        "            in_gen1 = ImageDataGenerator()\n",
        "            augment1 = random()\n",
        "            augment2 = random()\n",
        "            augment3 = random()\n",
        "            augment4 = random()\n",
        "            augment5 = random()\n",
        "            augment6 = random()\n",
        "\n",
        "            args = dict(tx = 0, ty = 0, zx = 1.0, zy= 1.0, flip_horizontal = False, flip_vertical = False)\n",
        "\n",
        "            if augment1>0.5:\n",
        "                args.update({'tx':50})\n",
        "\n",
        "            if augment2>0.5:\n",
        "                args.update({'ty':25})\n",
        "\n",
        "            if augment3>0.5:\n",
        "                args.update({'zx':0.9})\n",
        "\n",
        "            if augment4>0.5:\n",
        "                args.update({'zy':0.9})\n",
        "\n",
        "            if augment5>0.5:\n",
        "                args.update({'flip_horizontal' : True})\n",
        "\n",
        "            if augment6>0.5:\n",
        "                args.update({'flip_vertical' : True})\n",
        "\n",
        "            for i,h in enumerate(X):\n",
        "                X1[i] = in_gen1.apply_transform(h, transform_parameters = args)\n",
        "            for i,g in enumerate(y):\n",
        "                y1[i] = in_gen1.apply_transform(g, transform_parameters = args)\n",
        "            return X1, y1\n",
        "        else:\n",
        "            return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_N23trS_J0x",
        "colab": {}
      },
      "source": [
        "class test_DataGenerator_3(keras.utils.Sequence): # without augmentations for predictions\n",
        "    '''\n",
        "    The DataGenerator takes a batch of ImageIds of batch size 1 and returns Image array to the model with mask on validation\n",
        "    dataset and without mask on test dataset.\n",
        "    During Prediction and Evaluation stage Image augmentations are to not required. Thus this Train DataGenerator is modified \n",
        "    to create test Datagenerator\n",
        "    With the help of ImageIds the DataGenerator locates the Image file in the path, the image is read and resized from\n",
        "    256x1600 to 256x800.\n",
        "    Shuffling is disabled during predictions to make sure each prediction belongs to its corresponding ImageId.\n",
        "    '''\n",
        "    def __init__(self, df, batch_size = 1, shuffle=False, \n",
        "                 preprocess=None, info={}):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.preprocess = preprocess\n",
        "        self.info = info\n",
        "        self.data_path = '/content/A1_train/'\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __getitem__(self, index): \n",
        "        X = np.empty((self.batch_size,256,800,3),dtype=np.float32)\n",
        "        y = np.empty((self.batch_size,256,800,1),dtype=np.int8)\n",
        "\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n",
        "            self.info[index*self.batch_size+i]=f\n",
        "            X[i,] = Image.open(self.data_path + f).resize((800,256))      \n",
        "            y[i,:,:,0] = rle2maskResize(self.df['EncodedPixels'].iloc[indexes[i]])\n",
        "        if self.preprocess!=None: X = self.preprocess(X)\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5spKxvI_A-Cm"
      },
      "source": [
        "### 4.3.2 Segmentation Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FCuF2dqN_MZG",
        "colab": {}
      },
      "source": [
        "# https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/preprocessing.py\n",
        "# preprocesses image to input to the segmentation_model, generally image pixel value standardization\n",
        "preprocess = get_preprocessing('efficientnetb1') \n",
        "\n",
        "# https://github.com/qubvel/segmentation_models\n",
        "# segmentation using pretrained weights for faster convergence\n",
        "model = Unet('efficientnetb1', classes=1, activation='sigmoid', encoder_weights='imagenet') \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5skaCtswA-C1"
      },
      "source": [
        "### 4.3.3 Segmentation Model Training, Evaluation and Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lVaRhoV6A-C2"
      },
      "source": [
        "### I) Defect 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TvEwSk5L_x3b",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "if train_segmentation == True:\n",
        "    # TRAIN AND VALIDATE MODEL\n",
        "    # Defect 1\n",
        "    model.compile(optimizer='adam', loss=sm.losses.dice_loss,metrics=[dice_coef])\n",
        "    train_batches = train_DataGenerator_3(train_data_1,shuffle=True,preprocess=preprocess)    \n",
        "    valid_batches = test_DataGenerator_3(val_data_1,preprocess=preprocess)\n",
        "    \n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_Defect_1_01_02_2020'\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    \n",
        "    # https://keras.io/callbacks/\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_1_01_02_2020.h5', monitor='val_dice_coef', mode='max', verbose=1, save_best_only=True)\n",
        "    #model training\n",
        "    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    \n",
        "    # plotting the metric\n",
        "    vy = history.history['val_dice_coef']\n",
        "    ty = history.history['dice_coef']\n",
        "    x = list(range(1,len(vy)+1))\n",
        "    fig,ax = plt.subplots(1,1)\n",
        "    ax.plot(x,vy,'r',label = \"Validation dice\")\n",
        "    ax.plot(x,ty,'b',label = \"Train dice\")\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Metric: dice coef')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVmcjuZg_sC",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_1_tensorboard/train_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PBc6NZ4g_sC",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_1_tensorboard/val_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74rbK26Fg_sC",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Improvement of the Model performance at each epoch is smooth. It can also be observed that the model is not overfitting on the training set as the dice coefficien values on both the datasets are closer to each other and are improving simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0pnuWr7HA-C7"
      },
      "source": [
        "### Defect type 1: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UlJYxJiTAnd8",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_1_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7_ICWlCNF85E",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(test_DataGenerator_3(train_data_1,preprocess=preprocess),verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate, columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OtWhXlyAGD3d",
        "colab": {}
      },
      "source": [
        "validation_evaluate = model.evaluate(test_DataGenerator_3(val_data_1,preprocess=preprocess),verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(validation_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZIPvGEGGEbq",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_DataGenerator_3(test_data_1,preprocess=preprocess),verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5dTvcYDg_sK",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The values of dice coefficient metric for Defect 1 train, test and validation images can be seen to be far from each other. <br>\n",
        "\n",
        "**Dice loss = 1 - dice coefficient.**\n",
        "The performance of the model on dice_coefficient needs improvement which can be achieved by further training the model to 100+ epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecfYbJ7Mg_sK",
        "colab_type": "text"
      },
      "source": [
        "**Note:** Dice coefficient is also known as F1_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uPMr9ci4GMgM",
        "colab": {}
      },
      "source": [
        "# Train dataset prediction visualization\n",
        "train_preds = model.predict_generator(test_DataGenerator_3(train_data_1[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + train_data_1[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(train_data_1[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(train_data_1[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(train_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyM4SZupg_sM",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The above visualizations on training image dataset show how well the images are trained with supervised learning. The approximation in the predictions profile compered to true profile tells that the models can be further trained to identify the type 1 defects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9a-p4rCdGT-J",
        "colab": {}
      },
      "source": [
        "# Validation set\n",
        "val_preds = model.predict_generator(test_DataGenerator_3(val_data_1[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + val_data_1[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(val_data_1[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(val_data_1[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(val_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhM0sk7ig_sR",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The visualizations on validation dataset indicates that the model is performing well in identifying trained defect locations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSjrSzUnGZCa",
        "colab": {}
      },
      "source": [
        "# Test set\n",
        "test_preds = model.predict_generator(test_DataGenerator_3(test_data_1[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + test_data_1[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(test_data_1[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(test_data_1[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(test_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUWtkd_g_sT",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The above visualizations on test images tells us that the predicted locations of defect are similar to that of ground truth masks. The approximation in the predictions profile compered to true profile tells that the models can be further trained to identify the type 1 defects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "noBqigW0A-DA"
      },
      "source": [
        "### II) Defect 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQbg_PjXJ4W5",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "if train_segmentation == True:\n",
        "    # TRAIN AND VALIDATE MODEL\n",
        "    # Defect 2\n",
        "    model.compile(optimizer='adam', loss=sm.losses.dice_loss,metrics=[dice_coef])\n",
        "    train_batches = train_DataGenerator_3(train_data_2,shuffle=True,preprocess=preprocess)    \n",
        "    valid_batches = test_DataGenerator_3(val_data_2,preprocess=preprocess)\n",
        "    \n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_Defect_2_01_02_2020'\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    \n",
        "    # https://keras.io/callbacks/\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_2_01_02_2020.h5', monitor='val_dice_coef', mode='max', verbose=1, save_best_only=True)\n",
        "    #model training\n",
        "    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    \n",
        "    # plotting the metric\n",
        "    vy = history.history['val_dice_coef']\n",
        "    ty = history.history['dice_coef']\n",
        "    x = list(range(1,len(vy)+1))\n",
        "    fig,ax = plt.subplots(1,1)\n",
        "    ax.plot(x,vy,'r',label = \"Validation dice\")\n",
        "    ax.plot(x,ty,'b',label = \"Train dice\")\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Metric: dice coef')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Bb4gqEcg_sX",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_2_tensorboard/train_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7GK_rPvg_sX",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_2_tensorboard/val_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqS7D6H3g_sY",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** Dice coefficient can be seen to get stabilised in 0.65-0.7 range on validation set Thus, to improve performance number of training images should be increased and other Nueral Network architectures are required to be explored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FqzoEd0EA-DG"
      },
      "source": [
        "### Defect type 2: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TsYmU1jiJ4XM",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_2_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BkGjlDJBJ4XV",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(test_DataGenerator_3(train_data_2,preprocess=preprocess),verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate, columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tU3b5fbDJ4Xf",
        "colab": {}
      },
      "source": [
        "validation_evaluate = model.evaluate(test_DataGenerator_3(val_data_2,preprocess=preprocess),verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(validation_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3tHZXJ3IJ4Xo",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_DataGenerator_3(test_data_2,preprocess=preprocess),verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqEiHYRvg_sg",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The dice coefficient of test set and validation set predictions can be seen to be closer to each other which imples that the model is generalizing well on unseen images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MLHt3nWZJ4Xy",
        "colab": {}
      },
      "source": [
        "# Train dataset prediction visualization\n",
        "train_preds = model.predict_generator(test_DataGenerator_3(train_data_2[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + train_data_2[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(train_data_2[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(train_data_2[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(train_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPZJF8Mxg_si",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the training is satisfactory. The defect regional profiles can be seen to match in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LeXy3oseJ4X_",
        "colab": {}
      },
      "source": [
        "# Validation set\n",
        "val_preds = model.predict_generator(test_DataGenerator_3(val_data_2[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + val_data_2[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(val_data_2[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(val_data_2[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(val_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7jjOTBFg_sm",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kwIpGsc3J4YM",
        "colab": {}
      },
      "source": [
        "# Test set\n",
        "test_preds = model.predict_generator(test_DataGenerator_3(test_data_2[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + test_data_2[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(test_data_2[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(test_data_2[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(test_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bavE-SQDg_st",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7Mh-hA6LA-DN"
      },
      "source": [
        "### III) Defect 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RLszudFhLSVI",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "if train_segmentation == True:\n",
        "    # TRAIN AND VALIDATE MODEL\n",
        "    # Defect 3\n",
        "    model.compile(optimizer='adam', loss=sm.losses.dice_loss,metrics=[dice_coef])\n",
        "    train_batches = train_DataGenerator_3(train_data_3,shuffle=True,preprocess=preprocess)    \n",
        "    valid_batches = test_DataGenerator_3(val_data_3,preprocess=preprocess)\n",
        "    \n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_Defect_3_01_02_2020'\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    \n",
        "    # https://keras.io/callbacks/\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_3_01_02_2020.h5', monitor='val_dice_coef', mode='max', verbose=1, save_best_only=True)\n",
        "    #model training\n",
        "    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    \n",
        "    # plotting the metric\n",
        "    vy = history.history['val_dice_coef']\n",
        "    ty = history.history['dice_coef']\n",
        "    x = list(range(1,len(vy)+1))\n",
        "    fig,ax = plt.subplots(1,1)\n",
        "    ax.plot(x,vy,'r',label = \"Validation dice\")\n",
        "    ax.plot(x,ty,'b',label = \"Train dice\")\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Metric: dice coef')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyXEjbEsg_sw",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_3_tensorboard/train_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c1Nurpjg_sw",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_3_tensorboard/val_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jf8g-ySag_sw",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The model performance got constrained near 0.72 dice coefficient level on defect type 3. To improve the performance training for 100 + epochs is required while the Neural Network architecture can also be experimented with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4fgHTk1yA-DS"
      },
      "source": [
        "### Defect type 3: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tYNUtdKDLSVa",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_3_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZ1IR9z3LSVh",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(test_DataGenerator_3(train_data_3,preprocess=preprocess),verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate, columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P60NQnc9LSVr",
        "colab": {}
      },
      "source": [
        "validation_evaluate = model.evaluate(test_DataGenerator_3(val_data_3,preprocess=preprocess),verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(validation_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MXIrUAzpLSV3",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_DataGenerator_3(test_data_3,preprocess=preprocess),verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuLYvynkg_s3",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The dice coefficient of test set and validation set predictions can be seen to be closer to each other which imples that the model is generalizing well on unseen images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9utFrHfRLSV_",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "# Train dataset prediction visualization\n",
        "train_preds = model.predict_generator(test_DataGenerator_3(train_data_3[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + train_data_3[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(train_data_3[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(train_data_3[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(train_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tLqm0fTg_s6",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the training is satisfactory. The defect regional profiles can be seen to match in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "InKAgcPALSWJ",
        "colab": {}
      },
      "source": [
        "# Validation set\n",
        "val_preds = model.predict_generator(test_DataGenerator_3(val_data_3[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + val_data_3[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(val_data_3[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(val_data_3[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(val_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWhwWY8Ag_s8",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9hv-dvLLSWQ",
        "colab": {}
      },
      "source": [
        "# Test set\n",
        "test_preds = model.predict_generator(test_DataGenerator_3(test_data_3[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + test_data_3[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(test_data_3[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(test_data_3[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(test_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWMdp3A4g_s-",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YgWVoWyrA-DW"
      },
      "source": [
        "### IV) Defect 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8cdTy_BVL2sq",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "if train_segmentation == True:\n",
        "    # TRAIN AND VALIDATE MODEL\n",
        "    # Defect 4\n",
        "    model.compile(optimizer='adam', loss=sm.losses.dice_loss,metrics=[dice_coef])\n",
        "    train_batches = train_DataGenerator_3(train_data_4,shuffle=True,preprocess=preprocess)    \n",
        "    valid_batches = test_DataGenerator_3(val_data_4,preprocess=preprocess)\n",
        "    \n",
        "    # https://www.tensorflow.org/tensorboard/r2/scalars_and_keras\n",
        "    logdir = \"/content/drive/My Drive/severstal_february/severstal_logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'_Defect_4_01_02_2020'\n",
        "    file_writer = tf.summary.FileWriter(logdir + \"/metrics\")\n",
        "    tensorboard = keras.callbacks.TensorBoard(log_dir=logdir,histogram_freq=0,write_images=True)\n",
        "    \n",
        "    # https://keras.io/callbacks/\n",
        "    mc = ModelCheckpoint('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_4_01_02_2020.h5', monitor='val_dice_coef', mode='max', verbose=1, save_best_only=True)\n",
        "    #model training\n",
        "    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = epochs, verbose=1, callbacks = [mc,tensorboard])\n",
        "    \n",
        "    # plotting the metric\n",
        "    vy = history.history['val_dice_coef']\n",
        "    ty = history.history['dice_coef']\n",
        "    x = list(range(1,len(vy)+1))\n",
        "    fig,ax = plt.subplots(1,1)\n",
        "    ax.plot(x,vy,'r',label = \"Validation dice\")\n",
        "    ax.plot(x,ty,'b',label = \"Train dice\")\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.set_ylabel('Metric: dice coef')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    file_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHYqHG6Jg_tB",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_4_tensorboard/train_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvCrvdCrg_tB",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/defect_4_tensorboard/val_dice.jpg?raw=1' width=600px align = left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DH0P1Lsg_tB",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The model performance got constrained near 0.78 dice coefficient level on defect type 4. To improve the performance training for 100 + epochs is required while the Neural Network architecture can also be experimented with."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IgmmDfdHA-Dj"
      },
      "source": [
        "### Defect type 4: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAYBJL_dL2s5",
        "colab": {}
      },
      "source": [
        "model = load_model('/content/drive/My Drive/severstal_february/severstal_model/severstal_segmentation_Defect_4_01_02_2020.h5', custom_objects=dependencies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QxZPD4IaL2tA",
        "colab": {}
      },
      "source": [
        "train_evaluate = model.evaluate(test_DataGenerator_3(train_data_4,preprocess=preprocess),verbose=1)\n",
        "print('Train set evaluation score:')\n",
        "pd.DataFrame(train_evaluate, columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2TCqfgbL2tJ",
        "colab": {}
      },
      "source": [
        "validation_evaluate = model.evaluate(test_DataGenerator_3(val_data_4,preprocess=preprocess),verbose=1)\n",
        "print('Validation set evaluation score:')\n",
        "pd.DataFrame(validation_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Xddb6QWL2tS",
        "colab": {}
      },
      "source": [
        "test_evaluate = model.evaluate(test_DataGenerator_3(test_data_4,preprocess=preprocess),verbose=1)\n",
        "print('Test set evaluation score:')\n",
        "pd.DataFrame(test_evaluate,columns = [' '], index=['dice_loss','dice_coef'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsT8kp0g_tR",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The dice coefficient of test set and validation set predictions can be seen to be closer to each other which imples that the model is generalizing well on unseen images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HKMEjxUzL2tb",
        "colab": {}
      },
      "source": [
        "# Train dataset prediction visualization\n",
        "train_preds = model.predict_generator(test_DataGenerator_3(train_data_4[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + train_data_4[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(train_data_4[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(train_data_4[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(train_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98_n2JyjL2ti",
        "colab": {}
      },
      "source": [
        "# Validation set\n",
        "val_preds = model.predict_generator(test_DataGenerator_3(val_data_4[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + val_data_4[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(val_data_4[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(val_data_4[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(val_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POQkuxW6g_tY",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WDvuHdGNL2tr",
        "colab": {}
      },
      "source": [
        "# Test set\n",
        "test_preds = model.predict_generator(test_DataGenerator_3(test_data_4[10:20],preprocess=preprocess),verbose=1)\n",
        "for i in range(10):\n",
        "    fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(20, 13))\n",
        "    img = cv2.imread(str(\"/content/A1_train/\" + test_data_4[10:20].ImageId.values[i]))\n",
        "    ax1.imshow(img)\n",
        "    ax1.set_title(test_data_4[10:20].ImageId.values[i])\n",
        "\n",
        "    ax2.imshow(rle2mask(test_data_4[10:20].EncodedPixels.values[i]))\n",
        "    ax2.set_title('Ground Truth Mask')\n",
        "\n",
        "    c1 = Image.fromarray(test_preds[i][:,:,0])\n",
        "    ax3.imshow(np.array(c1.resize((1600,256)))>0.5)\n",
        "    ax3.set_title('Predicted Mask')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVFpyPylg_ta",
        "colab_type": "text"
      },
      "source": [
        "**Summary:** The evaluation visualization indicates that the model predictability is satisfactory. The defect regional profiles can be seen to match in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCTmoEh8g_ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/21892570/ipython-notebook-align-table-to-the-left-of-cell\n",
        "\n",
        "%%html\n",
        "<style>\n",
        "table {float:left}\n",
        "</style>\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_OY_bjCg_tc",
        "colab_type": "text"
      },
      "source": [
        "### Performance of the above trained models:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maA2d4C2g_tc",
        "colab_type": "text"
      },
      "source": [
        "**Binary Classifier:** <br>\n",
        "\n",
        "| Dataset | binary_crossentropy | acc | f1_score_m |precision_m | recall_m |\n",
        "| :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| X_train | 0.202241 | 0.923630 | 0.921999 | 0.949316 | 0.905966 |\n",
        "| X_val | 0.240638 | 0.912064 | 0.912423 | 0.937087 | 0.898664 |\n",
        "| X_test | 0.194755 | 0.926810 | 0.921435 | 0.955327 | 0.902135 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3PCGRE3g_tc",
        "colab_type": "text"
      },
      "source": [
        "**Multi Label Classifier:** <br>\n",
        "\n",
        "| Dataset | binary_crossentropy | acc | f1_score_m |precision_m | recall_m |\n",
        "| :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| X_train | 0.081054 | 0.968118 | 0.940510 | 0.945815 | 0.937232 |\n",
        "| X_val | 0.092119 | 0.962500| 0.929417 | 0.929264 | 0.931588 |\n",
        "| X_test | 0.094178 |  0.965517 | 0.936398 | 0.941134 | 0.933854 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GZEaNbsg_td",
        "colab_type": "text"
      },
      "source": [
        "**Segmentation models: Dice Coefficient:** <br>\n",
        "\n",
        "| Dataset | Defect 1 model | Defect 2 model | Defect 3 model | Defect 4 model |\n",
        "| :---: | :---: | :---: | :---: | :---: | :---: |\n",
        "| X_train | 0.714258 | 0.766948 | 0.735519 | 0.821943 |\n",
        "| X_val | 0.665121 | 0.678812 | 0.709641 | 0.76066 |\n",
        "| X_test | 0.611203 | 0.655394 | 0.698548 | 0.78822 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUekxOtgg_td",
        "colab_type": "text"
      },
      "source": [
        "## 5. Predictions and Kaggle Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8naxuYXFg_td",
        "colab_type": "text"
      },
      "source": [
        "See Inference.ipynb for how to make predictions on new images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abUEOqMFA-D2",
        "colab": {}
      },
      "source": [
        "Upload predictions on raw test data from final.ipynb to Kaggle as a Dataset and run the following code in a Kaggle Kernel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56BtczVjg_ti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\n",
        "df['EncodedPixels']=['' for i in range(len(df))]\n",
        "#df_submit = pd.read_csv(\"../input/sever-sub-13012020/sever_sub_13012020.csv\")\n",
        "df_submit = pd.read_csv(\"../input/sever-3101/severstal_final_test_preds_2.csv\").fillna('')\n",
        "if df.columns[0]=='ImageId_ClassId':\n",
        "    df.set_index('ImageId_ClassId', inplace=True)\n",
        "    df_submit.set_index('ImageId_ClassId', inplace=True)\n",
        "\n",
        "    for name, row in df_submit.iterrows():\n",
        "        df.loc[name] = row\n",
        "\n",
        "    df.reset_index(inplace=True)\n",
        "\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xAdZR9DyA-D7"
      },
      "source": [
        "### Mean Dice Coefficient of test data predictions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6liZDRI-g_tk"
      },
      "source": [
        "<img src='https://github.com/secutron/steel-defect-detection/blob/master/final_ipynb_score.jpg?raw=1' width=1200px align=left>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IgZg89MFA-EE"
      },
      "source": [
        "## 6. Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lXtJKUbg_tl",
        "colab_type": "text"
      },
      "source": [
        "1. Images and its masks (in form of EncodedPixels) are provided to train a Deep Learning Model to Detect and Classify defects in steel. (Multi-label Classification). The competition is hosted by Severstal on Kaggle.\n",
        "2. Exploratory Data Analysis revealed that the dataset is imbalanced. A new feature 'area' is created to clip predictions with segmentation areas within a determined range. Different classes are observed to overlap on smaller values of area feature. This makes class separation not possible based solely on 'area' feature. It was observed that most of the images either contain one defect or do not have a defect.\n",
        "3. A 6 model architecture is generated to train and test on this dataset. One binary classifier, One Multi-Label Classifier and Four segmentation models are used for the task. \n",
        "4. Image data contains minimal preprocessing. Pixel value scaling and Image augmentations for Model training are achieved using DataGenerators.\n",
        "5. Minority class priority based stratified sampling is performed on the dataset to split train set into train and validation sets.\n",
        "6. Pre-trained Deep Learning models are used: Xception architecture for Classification and legendary Unet architecture with efficientnetb1 backbone trained on ImageNet dataset for Segmentation.\n",
        "7. Tenosorboard is utilized for saving logs and visualizing model performance at each epoch. It has been observed that the models have satisfactory performance on defined metrics. It can also be deduced that a certain degree of confusion exists in both classification and segmentation models as the defect detection and loalization are not perfect. \n",
        "8. A final.ipynb notebook is submitted which is an inference version of this notebook."
      ]
    }
  ]
}